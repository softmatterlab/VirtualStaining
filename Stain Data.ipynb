{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1A - Virtual staining of brightfield images \n",
    "\n",
    "Example code to virtually stain brightfield images obtaining the corresponding images for nuclei, lipids and cytoplasm.\n",
    "\n",
    "This example can be used to virtually stain other brightfield images by changing the loading and saving user-defined in section 1.1. below.\n",
    "\n",
    "version 1.0 <br />\n",
    "15 November 2020 <br />\n",
    "Benjamin Midtvedt, Jes√∫s Pineda Castro, Saga Helgadottir, Daniel Midtvedt & Giovanni Volpe <br />\n",
    "Soft Matter Lab @ GU <br />\n",
    "http://www.softmatterlab.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports\n",
    " \n",
    "Import all necessary packages. These include standard Python packages as well as the core of DeepTrack 2.0 (`deeptrack`) and some specialized classes for this virtual staining (`apido`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import itertools\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# DeepTrack 2.0 code\n",
    "import apido\n",
    "from apido import deeptrack as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define input and output\n",
    "\n",
    "Set constants to determine the input and output images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 User-defined constants to load test images and save the virtually stained images\n",
    "\n",
    "Constants defined by the user:\n",
    "\n",
    "* `DATASET`: Name of dataset\n",
    "\n",
    "* `OUTPUT_PATH`: Output path (not including the magnication folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"apidocytes_60x\" \n",
    "file_name_struct = \"AssayPlate_Greiner_#655090_{well}_T0001F{site}L01A0{action}Z0{focus}C0{action}.tif\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Inferred constants\n",
    "\n",
    "Constants automatically inferred from the user input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infer and normalize paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = os.path.normpath(os.path.join(\"datasets\", DATASET))\n",
    "VALIDATION_PATH = os.path.join(DATASET_PATH, \"validation_data\")\n",
    "OUTPUT_PATH = os.path.join(DATASET_PATH, \"validation_results\")\n",
    "\n",
    "PATH_TO_MODEL = os.path.normpath(os.path.join(DATASET_PATH, \"model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from: \t\t datasets\\apidocytes_60x\\validation_data\n",
      "Saving results to: \t\t datasets\\apidocytes_60x\\validation_results\n",
      "Loading pretrained model from: \t datasets\\apidocytes_60x\\model\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading images from: \\t\\t\", VALIDATION_PATH)\n",
    "print(\"Saving results to: \\t\\t\", OUTPUT_PATH)\n",
    "print(\"Loading pretrained model from: \\t\", PATH_TO_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load model\n",
    "\n",
    "Load the pretrained virtual stainer from the local path.\n",
    "\n",
    "Note that we expect here some warnings about overwriting `groups`, which are not a problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, None, None, 7 0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, None, None, 1 1024        lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization (Instanc (None, None, None, 1 32          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         multiple             0           instance_normalization[0][0]     \n",
      "                                                                 instance_normalization_1[0][0]   \n",
      "                                                                 instance_normalization_2[0][0]   \n",
      "                                                                 instance_normalization_3[0][0]   \n",
      "                                                                 instance_normalization_4[0][0]   \n",
      "                                                                 instance_normalization_5[0][0]   \n",
      "                                                                 instance_normalization_6[0][0]   \n",
      "                                                                 instance_normalization_7[0][0]   \n",
      "                                                                 instance_normalization_8[0][0]   \n",
      "                                                                 instance_normalization_9[0][0]   \n",
      "                                                                 instance_normalization_10[0][0]  \n",
      "                                                                 add[0][0]                        \n",
      "                                                                 instance_normalization_12[0][0]  \n",
      "                                                                 instance_normalization_13[0][0]  \n",
      "                                                                 instance_normalization_14[0][0]  \n",
      "                                                                 instance_normalization_15[0][0]  \n",
      "                                                                 instance_normalization_16[0][0]  \n",
      "                                                                 instance_normalization_17[0][0]  \n",
      "                                                                 instance_normalization_18[0][0]  \n",
      "                                                                 instance_normalization_19[0][0]  \n",
      "                                                                 instance_normalization_20[0][0]  \n",
      "                                                                 instance_normalization_21[0][0]  \n",
      "                                                                 instance_normalization_22[0][0]  \n",
      "                                                                 instance_normalization_23[0][0]  \n",
      "                                                                 instance_normalization_24[0][0]  \n",
      "                                                                 instance_normalization_25[0][0]  \n",
      "                                                                 instance_normalization_26[0][0]  \n",
      "                                                                 instance_normalization_27[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, None, None, 1 2320        leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_1 (Insta (None, None, None, 1 32          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, None, None, 2 0           leaky_re_lu[1][0]                \n",
      "                                                                 lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, None, None, 2 0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, None, None, 3 6656        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_2 (Insta (None, None, None, 3 64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, None, None, 3 9248        leaky_re_lu[2][0]                \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_3 (Insta (None, None, None, 3 64          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, None, 5 0           leaky_re_lu[3][0]                \n",
      "                                                                 max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, None, None, 5 0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, None, None, 6 31744       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_4 (Insta (None, None, None, 6 128         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, None, None, 6 36928       leaky_re_lu[4][0]                \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_5 (Insta (None, None, None, 6 128         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, None, None, 1 0           leaky_re_lu[5][0]                \n",
      "                                                                 max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, None, None, 1 0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, None, None, 1 137216      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_6 (Insta (None, None, None, 1 256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, None, None, 1 147584      leaky_re_lu[6][0]                \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_7 (Insta (None, None, None, 1 256         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, None, None, 2 0           leaky_re_lu[7][0]                \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, None, None, 2 0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, None, None, 2 569344      max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_8 (Insta (None, None, None, 2 512         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, None, None, 2 590080      leaky_re_lu[8][0]                \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_9 (Insta (None, None, None, 2 512         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, None, None, 5 0           leaky_re_lu[9][0]                \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, None, None, 5 0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, None, None, 5 2318336     max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_10 (Inst (None, None, None, 5 1024        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, None, None, 5 2359808     leaky_re_lu[10][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, None, None, 5 258048      max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_11 (Inst (None, None, None, 5 1024        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, None, None, 5 0           conv2d_10[0][0]                  \n",
      "                                                                 instance_normalization_11[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, None, None, 5 0           leaky_re_lu[11][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, None, None, 7 0           up_sampling2d[0][0]              \n",
      "                                                                 leaky_re_lu[9][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, None, None, 2 1769728     concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_12 (Inst (None, None, None, 2 512         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, None, None, 2 590080      leaky_re_lu[12][0]               \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_13 (Inst (None, None, None, 2 512         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, None, None, 2 0           leaky_re_lu[13][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, None, None, 3 0           up_sampling2d_1[0][0]            \n",
      "                                                                 leaky_re_lu[7][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, None, None, 1 442496      concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_14 (Inst (None, None, None, 1 256         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, None, None, 1 147584      leaky_re_lu[14][0]               \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_15 (Inst (None, None, None, 1 256         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, None, None, 1 0           leaky_re_lu[15][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, None, None, 1 0           up_sampling2d_2[0][0]            \n",
      "                                                                 leaky_re_lu[5][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, None, None, 6 110656      concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_16 (Inst (None, None, None, 6 128         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, None, None, 6 36928       leaky_re_lu[16][0]               \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_17 (Inst (None, None, None, 6 128         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, None, None, 6 0           leaky_re_lu[17][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, None, None, 9 0           up_sampling2d_3[0][0]            \n",
      "                                                                 leaky_re_lu[3][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, None, None, 3 27680       concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_18 (Inst (None, None, None, 3 64          conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, None, None, 3 9248        leaky_re_lu[18][0]               \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_19 (Inst (None, None, None, 3 64          conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, None, None, 3 0           leaky_re_lu[19][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, None, None, 4 0           up_sampling2d_4[0][0]            \n",
      "                                                                 leaky_re_lu[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, None, None, 1 6928        concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_20 (Inst (None, None, None, 1 32          conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, None, None, 1 2320        leaky_re_lu[20][0]               \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_21 (Inst (None, None, None, 1 32          conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, None, None, 1 2320        leaky_re_lu[21][0]               \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_22 (Inst (None, None, None, 1 32          conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, None, None, 8 1160        leaky_re_lu[22][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, None, None, 1 2320        leaky_re_lu[21][0]               \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_25 (Inst (None, None, None, 8 16          conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_23 (Inst (None, None, None, 1 32          conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, None, None, 8 1160        leaky_re_lu[23][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, None, None, 1 2320        leaky_re_lu[21][0]               \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_26 (Inst (None, None, None, 8 16          conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_24 (Inst (None, None, None, 1 32          conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, None, None, 8 1160        leaky_re_lu[24][0]               \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_27 (Inst (None, None, None, 8 16          conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, None, None, 1 9           leaky_re_lu[25][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, None, None, 1 9           leaky_re_lu[26][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, None, None, 1 9           leaky_re_lu[27][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, None, None, 3 0           conv2d_34[0][0]                  \n",
      "                                                                 conv2d_35[0][0]                  \n",
      "                                                                 conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "scale_layer (ScaleLayer)        (None, None, None, 3 6           concatenate_10[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 9,628,617\n",
      "Trainable params: 9,628,617\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "virtual_stainer = apido.load_model(os.path.abspath(PATH_TO_MODEL))\n",
    "virtual_stainer.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load input data\n",
    "\n",
    "We define a data pipeline to load brightfield images from storage. This uses DeepTrack 2.0, and follows the structure:\n",
    "\n",
    "1. Load dataset parameters calculated before training.\n",
    "2. Load each z-slice of a well-site combination and concatenate them.\n",
    "3. Pad the volume such that the first two dimensions are multiples of 32 (required by the model).\n",
    "4. Correct for misalignment of the fluorescence channel and the brightfield channel (by a pre-calculated parametrization of the offset as a function of magnification and the site)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = apido.get_dataset_parameters(DATASET)\n",
    "binned_offset = params.bin(\"offset\", \"site\", reducer=np.mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Find all wells and sites\n",
    "\n",
    "We create an list over each well and site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = glob.glob(os.path.join(VALIDATION_PATH, \"*C01.tif\"))\n",
    "\n",
    "SITES = [re.findall(\"F([0-9]{3})\", f)[-1] for f in file_list]\n",
    "WELLS = [re.findall(\"_([A-Z][0-9]{2})_\", f)[-1] for f in file_list]\n",
    "\n",
    "wells_and_sites = list(zip(WELLS, SITES))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 The root feature\n",
    "\n",
    "We use DeepTrack 2.0 to define the data loader pipeline. The pipeline is a sequence of `features`, which perform computations, controlled by `properties`, which are defined when creating the features. (Note that we any property with any name and value to a feature; if a property is not used by the feature, we refer to it as a dummy property.)\n",
    "\n",
    "The feature `root` is a `DummyFeature`, which is just a container of dummy properties and does not perform any computations.\n",
    "It takes the following arguments:\n",
    "\n",
    "* `well_site_tuple` is a dummy property that cycles through the well-site combinations in `wells_and_sites`\n",
    "* `well` is a dummy property that extracts the well from the `well_site_tuple`\n",
    "* `site` is a dummy property that extracts the site from the `well_site_tuple`\n",
    "\n",
    "Note that `well` and `site` are functions that take `well_site_tuple` as argument. These are dependent properties, and DeepTrack 2.0 will automatically ensure that they receive the correct input.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = dt.DummyFeature(\n",
    "    well_site_tuple=itertools.cycle(wells_and_sites), # On each update, root will grab the next value from this iterator\n",
    "    well=lambda well_site_tuple: well_site_tuple[0],  # Grabs the well from the well_site_tuple\n",
    "    site=lambda well_site_tuple: well_site_tuple[1],  # Grabs the site from the well_site_tuple\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 The brightfield image loader\n",
    "\n",
    "We use `deeptrack.LoadImage` to load and concatenate a brightfield stack. It takes the following arguments:\n",
    "\n",
    "* `**root.properties` means that we take the properties of `root` (of importance `well` and `site`). The other properties of LoadImage will now depend on these.\n",
    "* `file_names` is a dummy property, which takes the current well and site as input, and creates a list of file names that we want to load.\n",
    "* `path` is a property used by `LoadImage` to determine which files to load. We calculate it by taking `file_names` as input and returning a list of paths using `os.path.join`.\n",
    "\n",
    "Since `path` is a list, `LoadImage` stacks the images along the last dimension, creating a shaped volume with dimensions (width, height, 7)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "brightfield_loader = dt.LoadImage(\n",
    "    **root.properties,\n",
    "    file_names=lambda well, site: [file_name_struct.format(well=well, site=site, action=4, focus=z) for z in range(1, 8)],\n",
    "    path=lambda file_names: [os.path.join(VALIDATION_PATH, file_name) for file_name in file_names],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Padding\n",
    "\n",
    "The model requires the two primary dimensions of the input to be multiples of 32. We ensure this using `deeptrack.PadToMultiplesOf`. This feature also adds a property which allows us to restore the model prediction to the original shape. It takes the following argument:\n",
    "\n",
    "* `multiple` is a tuple of multiples per dimension. In our case, we set the first two dimentsions to 32 and the third dimension to `None` (meaning that we do not want to pad it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensure_padded = dt.PadToMultiplesOf(multiple=(32, 32, None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Offset adjustment\n",
    "\n",
    "Offset adjustments using affine transformations. The offset is parametrized as a function of the magnification and the site as described in the report.\n",
    "\n",
    "The properties are set as follows:\n",
    "* `translate` sets how much we translate the image in pixels. It is a tuple representing the (x, y) shift. We calculate it as a function of the angular position of the site within the well, with site 1 at angle 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affine transformation parameters (precalculated, see report)\n",
    "\n",
    "correct_offset = dt.Affine(\n",
    "    translate=lambda site: binned_offset[site],\n",
    "    **root.properties\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Create the pipeline \n",
    "\n",
    "We use the `+` operator to chain the features, defining the execution order. In DeepTrack 2.0, this means that the output of the feature on the left is passed as the input to the feature on the right. In other words, the stack loaded by `brightfield_loader` is passed to `ensure_padded`, the output of which is offset-corrected by `correct_offset`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "brightfield_stack_pipeline = brightfield_loader + ensure_padded + correct_offset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calculate the virtually stained images from the brightfield images\n",
    "\n",
    "In order to have the actual brightfield images needed for further processing, we need to resolve the pipeline `brightfield_stack_pipeline`.\n",
    "\n",
    "Each time we call `update()`, we update each property of all the features in the pipeline, ensuring that each dependent property is updated in the right order. Therefore, at each update, we select a new well-site combination, from which we obtain all other properties (the path of the images, the angle of the site, etc.).\n",
    "\n",
    "The subsequent call to `resolve()` executes each feature in the pipeline in order, producing a brightfield stack.\n",
    "\n",
    "We do this once per image we want to load, for a total number of images set in `num_files`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 15 files\n"
     ]
    }
   ],
   "source": [
    "num_files = len(wells_and_sites)\n",
    "\n",
    "print(\"Loading {0} files\".format(num_files))\n",
    "list_of_brightfield_images = [\n",
    "    brightfield_stack_pipeline.update().resolve() for _ in range(num_files)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time the execution time. Set `TIME_EXECUTION` to `False` to bypass!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished iteration 0\n",
      "Finished iteration 1\n",
      "Finished iteration 2\n",
      "Finished iteration 3\n",
      "Finished iteration 4\n",
      "Finished iteration 5\n",
      "Finished iteration 6\n",
      "Finished iteration 7\n",
      "Finished iteration 8\n",
      "Finished iteration 9\n",
      "Finished iteration 10\n",
      "Finished iteration 11\n",
      "Finished iteration 12\n",
      "Finished iteration 13\n",
      "Finished iteration 14\n",
      "Made 210 predictions in 230.48671959999973 seconds. Median 1.1050971800000033 seconds per image, minimum of 0.8236257999999983 seconds, not bad!\n"
     ]
    }
   ],
   "source": [
    "TIME_EXECUTION = False\n",
    "ITERATIONS = 15\n",
    "\n",
    "model_input = np.array(list_of_brightfield_images)\n",
    "\n",
    "if TIME_EXECUTION:\n",
    "    \n",
    "    timings = []\n",
    "    \n",
    "    for iteration in range(ITERATIONS):\n",
    "        start = timer()\n",
    "        virtual_stainer.predict(model_input, batch_size=1)\n",
    "        end = timer()\n",
    "        timings.append(end - start)\n",
    "\n",
    "        print(\"Finished iteration\", iteration)\n",
    "    \n",
    "    num_predictions = num_files * (ITERATIONS - 1)\n",
    "    timings = timings[1:] # Skipping first iteration to ignore cold-start\n",
    "\n",
    "    \n",
    "    print(\n",
    "        \"Made {0} predictions in {1} seconds. Median {2} seconds per image, minimum of {3} seconds, not bad!\"\n",
    "        .format(num_predictions, np.sum(timings), np.median(timings) / num_files, np.min(timings) / num_files)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we calculate the virtual staining. All we need to do is to call `virtual_stainer.predict`, no further pre- or post-processing needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "stains = virtual_stainer.predict(model_input, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save results\n",
    "\n",
    "Finally, we iterate over all the virtually stained images and store the results to memory. In DeepTrack 2.0, the properties used to create an image with `resolve()` are stored in a field called `properties`, and can easily be retrieved using the utility method `get_property`. Here, we use this information to extract the well and site of the image, which is needed to correctly name the file. Moreover, some features save additional values. One such case is `undo_padding` which is saved by all padding features. This is a tuple of slices that return an numpy array to its original size before padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "\n",
    "for brightfield, prediction in zip(list_of_brightfield_images, stains):\n",
    "    \n",
    "    well = brightfield.get_property(\"well\")\n",
    "    site = brightfield.get_property(\"site\")\n",
    "    \n",
    "    # Undo the padding required by the model\n",
    "    undo_padding = brightfield.get_property(\"undo_padding\")\n",
    "    prediction = prediction[undo_padding]\n",
    "    for action in range(3):\n",
    "        file_path = output_format.format(well=well, site=site, action=action + 1, focus=1)\n",
    "        \n",
    "        prediction_layer = Image.fromarray(prediction[..., action].astype(np.uint16))\n",
    "        prediction_layer.save(file_path)\n",
    "\n",
    "        print(\"Saved image to:\", file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
