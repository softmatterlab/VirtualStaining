{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1A - Virtual staining of brightfield images (60x)\n",
    "\n",
    "Example code to virtually stain brightfield images captured with the 60x magnification objective obtaining the corresponding images for nuclei, lipids and cytoplasm.\n",
    "\n",
    "This example can be used to virtually stain other brightfield images by changing the loading and saving user-defined in section 1.1. below.\n",
    "\n",
    "version 1.0 <br />\n",
    "15 November 2020 <br />\n",
    "Benjamin Midtvedt, Jes√∫s Pineda Castro, Saga Helgadottir, Daniel Midtvedt & Giovanni Volpe <br />\n",
    "Soft Matter Lab @ GU <br />\n",
    "http://www.softmatterlab.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports\n",
    " \n",
    "Import all necessary packages. These include standard Python packages as well as the core of DeepTrack 2.0 (`deeptrack`) and some specialized classes for this virtual staining (`apido`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import itertools\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# DeepTrack 2.0 code\n",
    "import apido\n",
    "from apido import deeptrack as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define input and output\n",
    "\n",
    "Set constants to determine the input and output images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 User-defined constants to load test images and save the virtually stained images\n",
    "\n",
    "Constants defined by the user:\n",
    "\n",
    "* `DATASET_PATH`: Input path (not including the magnification folder)\n",
    "\n",
    "* `OUTPUT_PATH`: Output path (not including the magnication folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"./validation_data/60x images/\" \n",
    "OUTPUT_PATH = \"./validation_results/60x images/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Inferred constants\n",
    "\n",
    "Constants automatically inferred from the user input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAGNIFICATION = \"60x\"\n",
    "file_name_struct = \"AssayPlate_Greiner_#655090_{0}_T0001F{1}L01A0{2}Z0{3}C0{2}.tif\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infer and normalize paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = os.path.normpath(DATASET_PATH)\n",
    "OUTPUT_PATH = os.path.normpath(OUTPUT_PATH)\n",
    "\n",
    "PATH_TO_MODEL = os.path.normpath(\n",
    "    os.path.abspath(\n",
    "        os.path.join(\"models\", MAGNIFICATION)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from: \t\t validation_data\\60x images\n",
      "Saving results to: \t\t validation_results\\60x images\n",
      "Loading pretrained model from: \t C:\\Users\\bmidt\\Master Thesis\\VirtualStaining\\models\\60x\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading images from: \\t\\t\", DATASET_PATH)\n",
    "print(\"Saving results to: \\t\\t\", OUTPUT_PATH)\n",
    "print(\"Loading pretrained model from: \\t\", PATH_TO_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load model\n",
    "\n",
    "Load the pretrained virtual stainer from the local path.\n",
    "\n",
    "Note that we expect here some warnings about overwriting `groups`, which are not a problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Folder C:\\Users\\bmidt\\Master Thesis\\VirtualStaining\\models\\60x does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-af49da5b3aa7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvirtual_stainer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapido\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPATH_TO_MODEL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mvirtual_stainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Master Thesis\\VirtualStaining\\apido\\utils.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(folder)\u001b[0m\n\u001b[0;32m    250\u001b[0m     \u001b[0mfolder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m     \u001b[1;32massert\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Folder {0} does not exist\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[0mmodel_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_model_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Folder C:\\Users\\bmidt\\Master Thesis\\VirtualStaining\\models\\60x does not exist"
     ]
    }
   ],
   "source": [
    "virtual_stainer = apido.load_model(PATH_TO_MODEL)\n",
    "virtual_stainer.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load input data\n",
    "\n",
    "We define a data pipeline to load brightfield images from storage. This uses DeepTrack 2.0, and follows the structure:\n",
    "\n",
    "1. Load each z-slice of a well-site combination and concatenate them.\n",
    "2. Pad the volume such that the first two dimensions are multiples of 32 (required by the model).\n",
    "3. Correct for misalignment of the fluorescence channel and the brightfield channel (by a pre-calculated parametrization of the offset as a function of magnification and the site)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Find all wells and sites\n",
    "\n",
    "We create an list over each well and site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = glob.glob(os.path.join(DATASET_PATH, \"*C01.tif\"))\n",
    "\n",
    "SITES = [re.findall(\"F([0-9]{3})\", f)[-1] for f in file_list]\n",
    "WELLS = [re.findall(\"_([A-Z][0-9]{2})_\", f)[-1] for f in file_list]\n",
    "\n",
    "wells_and_sites = list(zip(WELLS, SITES))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 The root feature\n",
    "\n",
    "We use DeepTrack 2.0 to define the data loader pipeline. The pipeline is a sequence of `features`, which perform computations, controlled by `properties`, which are defined when creating the features. (Note that we any property with any name and value to a feature; if a property is not used by the feature, we refer to it as a dummy property.)\n",
    "\n",
    "The feature `root` is a `DummyFeature`, which is just a container of dummy properties and does not perform any computations.\n",
    "It takes the following arguments:\n",
    "\n",
    "* `well_site_tuple` is a dummy property that cycles through the well-site combinations in `wells_and_sites`\n",
    "* `well` is a dummy property that extracts the well from the `well_site_tuple`\n",
    "* `site` is a dummy property that extracts the site from the `well_site_tuple`\n",
    "\n",
    "Note that `well` and `site` are functions that take `well_site_tuple` as argument. These are dependent properties, and DeepTrack 2.0 will automatically ensure that they receive the correct input.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = dt.DummyFeature(\n",
    "    well_site_tuple=itertools.cycle(wells_and_sites), # On each update, root will grab the next value from this iterator\n",
    "    well=lambda well_site_tuple: well_site_tuple[0],  # Grabs the well from the well_site_tuple\n",
    "    site=lambda well_site_tuple: well_site_tuple[1],  # Grabs the site from the well_site_tuple\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 The brightfield image loader\n",
    "\n",
    "We use `deeptrack.LoadImage` to load and concatenate a brightfield stack. It takes the following arguments:\n",
    "\n",
    "* `**root.properties` means that we take the properties of `root` (of importance `well` and `site`). The other properties of LoadImage will now depend on these.\n",
    "* `file_names` is a dummy property, which takes the current well and site as input, and creates a list of file names that we want to load.\n",
    "* `path` is a property used by `LoadImage` to determine which files to load. We calculate it by taking `file_names` as input and returning a list of paths using `os.path.join`.\n",
    "\n",
    "Since `path` is a list, `LoadImage` stacks the images along the last dimension, creating a shaped volume with dimensions (width, height, 7)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "brightfield_loader = dt.LoadImage(\n",
    "    **root.properties,\n",
    "    file_names=lambda well, site: [file_name_struct.format(well, site, 4, z) for z in range(1, 8)],\n",
    "    path=lambda file_names: [os.path.join(DATASET_PATH, file_name) for file_name in file_names],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Padding\n",
    "\n",
    "The model requires the two primary dimensions of the input to be multiples of 32. We ensure this using `deeptrack.PadToMultiplesOf`. This feature also adds a property which allows us to restore the model prediction to the original shape. It takes the following argument:\n",
    "\n",
    "* `multiple` is a tuple of multiples per dimension. In our case, we set the first two dimentsions to 32 and the third dimension to `None` (meaning that we do not want to pad it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensure_padded = dt.PadToMultiplesOf(multiple=(32, 32, None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Offset adjustment\n",
    "\n",
    "Offset adjustments using affine transformations. The offset is parametrized as a function of the magnification and the site as described in the report.\n",
    "\n",
    "The properties are set as follows:\n",
    "* `translate` sets how much we translate the image in pixels. It is a tuple representing the (x, y) shift. We calculate it as a function of the angular position of the site within the well, with site 1 at angle 0.\n",
    "* `scale` sets how much we rescale the image.\n",
    "* `angle` is a dummy property that calculates the angle of the site in radians."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affine transformation parameters (precalculate, see report)\n",
    "Ax = +2.3054\n",
    "Bx = -0.0315\n",
    "Ay = -0.1352\n",
    "By = -2.3049\n",
    "x =  -0.8363\n",
    "y =  +0.8081\n",
    "scale= 0.99975\n",
    "\n",
    "correct_offset = dt.Affine(\n",
    "    translate=lambda angle: (\n",
    "        (np.cos(angle) * Bx + np.sin(angle) * Ax + x) * -1, # Offset in x\n",
    "        (np.cos(angle) * By + np.sin(angle) * Ay + y) * -1, # Offset in y\n",
    "    ),\n",
    "    scale=scale,\n",
    "    angle = lambda site: (int(site) - 1) * np.pi / 6,\n",
    "    **root.properties,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Create the pipeline \n",
    "\n",
    "We use the `+` operator to chain the features, defining the execution order. In DeepTrack 2.0, this means that the output of the feature on the left is passed as the input to the feature on the right. In other words, the stack loaded by `brightfield_loader` is passed to `ensure_padded`, the output of which is offset-corrected by `correct_offset`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "brightfield_stack_pipeline = brightfield_loader + ensure_padded + correct_offset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calculate the virtually stained images from the brightfield images\n",
    "\n",
    "In order to have the actual brightfield images needed for further processing, we need to resolve the pipeline `brightfield_stack_pipeline`.\n",
    "\n",
    "Each time we call `update()`, we update each property of all the features in the pipeline, ensuring that each dependent property is updated in the right order. Therefore, at each update, we select a new well-site combination, from which we obtain all other properties (the path of the images, the angle of the site, etc.).\n",
    "\n",
    "The subsequent call to `resolve()` executes each feature in the pipeline in order, producing a brightfield stack.\n",
    "\n",
    "We do this once per image we want to load, for a total number of images set in `num_files`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 15 files\n"
     ]
    }
   ],
   "source": [
    "num_files = len(wells_and_sites)\n",
    "\n",
    "print(\"Loading {0} files\".format(num_files))\n",
    "list_of_brightfield_images = [\n",
    "    brightfield_stack_pipeline.update().resolve() for _ in range(num_files)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time the execution time. Set `TIME_EXECUTION` to `False` to bypass!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_EXECUTION = False\n",
    "ITERATIONS = 15\n",
    "\n",
    "model_input = np.array(list_of_brightfield_images)\n",
    "\n",
    "if TIME_EXECUTION:\n",
    "    \n",
    "    timings = []\n",
    "    \n",
    "    for iteration in range(ITERATIONS):\n",
    "        start = timer()\n",
    "        virtual_stainer.predict(model_input, batch_size=4)\n",
    "        end = timer()\n",
    "        timings.append(end - start)\n",
    "\n",
    "        print(\"Finished iteration\", iteration)\n",
    "    \n",
    "    num_predictions = num_files * (ITERATIONS - 1)\n",
    "    timings = timings[1:] # Skipping first iteration to ignore cold-start\n",
    "\n",
    "    \n",
    "    print(\n",
    "        \"Made {0} predictions in {1} seconds. Median {2} seconds per image, minimum of {3} seconds, not bad!\"\n",
    "        .format(num_predictions, np.sum(timings), np.median(timings) / num_files, np.min(timings) / num_files)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we calculate the virtual staining. All we need to do is to call `virtual_stainer.predict`, no further pre- or post-processing needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stains = virtual_stainer.predict(model_input, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save results\n",
    "\n",
    "Finally, we iterate over all the virtually stained images and store the results to memory. In DeepTrack 2.0, the properties used to create an image with `resolve()` are stored in a field called `properties`, and can easily be retrieved using the utility method `get_property`. Here, we use this information to extract the well and site of the image, which is needed to correctly name the file. Moreover, some features save additional values. One such case is `undo_padding` which is saved by all padding features. This is a tuple of slices that return an numpy array to its original size before padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved image to: validation_results\\60x images\\AssayPlate_Greiner_#655090_B03_T0001F001L01A01Z01C01.tif\n",
      "Saved image to: validation_results\\60x images\\AssayPlate_Greiner_#655090_B03_T0001F001L01A02Z01C02.tif\n",
      "Saved image to: validation_results\\60x images\\AssayPlate_Greiner_#655090_B03_T0001F001L01A03Z01C03.tif\n",
      "Saved image to: validation_results\\60x images\\AssayPlate_Greiner_#655090_B03_T0001F002L01A01Z01C01.tif\n",
      "Saved image to: validation_results\\60x images\\AssayPlate_Greiner_#655090_B03_T0001F002L01A02Z01C02.tif\n",
      "Saved image to: validation_results\\60x images\\AssayPlate_Greiner_#655090_B03_T0001F002L01A03Z01C03.tif\n",
      "Saved image to: validation_results\\60x images\\AssayPlate_Greiner_#655090_B03_T0001F010L01A01Z01C01.tif\n",
      "Saved image to: validation_results\\60x images\\AssayPlate_Greiner_#655090_B03_T0001F010L01A02Z01C02.tif\n",
      "Saved image to: validation_results\\60x images\\AssayPlate_Greiner_#655090_B03_T0001F010L01A03Z01C03.tif\n",
      "Saved image to: validation_results\\60x images\\AssayPlate_Greiner_#655090_B04_T0001F001L01A01Z01C01.tif\n",
      "Saved image to: validation_results\\60x images\\AssayPlate_Greiner_#655090_B04_T0001F001L01A02Z01C02.tif\n",
      "Saved image to: validation_results\\60x images\\AssayPlate_Greiner_#655090_B04_T0001F001L01A03Z01C03.tif\n",
      "Saved image to: validation_results\\60x images\\AssayPlate_Greiner_#655090_B04_T0001F003L01A01Z01C01.tif\n",
      "Saved image to: validation_results\\60x images\\AssayPlate_Greiner_#655090_B04_T0001F003L01A02Z01C02.tif\n",
      "Saved image to: validation_results\\60x images\\AssayPlate_Greiner_#655090_B04_T0001F003L01A03Z01C03.tif\n",
      "Saved image to: validation_results\\60x images\\AssayPlate_Greiner_#655090_B04_T0001F004L01A01Z01C01.tif\n",
      "Saved image to: validation_results\\60x images\\AssayPlate_Greiner_#655090_B04_T0001F004L01A02Z01C02.tif\n",
      "Saved image to: validation_results\\60x images\\AssayPlate_Greiner_#655090_B04_T0001F004L01A03Z01C03.tif\n",
      "Saved image to: validation_results\\60x images\\AssayPlate_Greiner_#655090_C02_T0001F001L01A01Z01C01.tif\n",
      "Saved image to: validation_results\\60x images\\AssayPlate_Greiner_#655090_C02_T0001F001L01A02Z01C02.tif\n",
      "Saved image to: validation_results\\60x images\\AssayPlate_Greiner_#655090_C02_T0001F001L01A03Z01C03.tif\n",
      "Saved image to: validation_results\\60x images\\AssayPlate_Greiner_#655090_C02_T0001F004L01A01Z01C01.tif\n",
      "Saved image to: validation_results\\60x images\\AssayPlate_Greiner_#655090_C02_T0001F004L01A02Z01C02.tif\n",
      "Saved image to: validation_results\\60x images\\AssayPlate_Greiner_#655090_C02_T0001F004L01A03Z01C03.tif\n",
      "Saved image to: validation_results\\60x images\\AssayPlate_Greiner_#655090_C02_T0001F006L01A01Z01C01.tif\n",
      "Saved image to: validation_results\\60x images\\AssayPlate_Greiner_#655090_C02_T0001F006L01A02Z01C02.tif\n",
      "Saved image to: validation_results\\60x images\\AssayPlate_Greiner_#655090_C02_T0001F006L01A03Z01C03.tif\n",
      "Saved image to: validation_results\\60x images\\AssayPlate_Greiner_#655090_C04_T0001F004L01A01Z01C01.tif\n",
      "Saved image to: validation_results\\60x images\\AssayPlate_Greiner_#655090_C04_T0001F004L01A02Z01C02.tif\n",
      "Saved image to: validation_results\\60x images\\AssayPlate_Greiner_#655090_C04_T0001F004L01A03Z01C03.tif\n",
      "Saved image to: validation_results\\60x images\\AssayPlate_Greiner_#655090_C04_T0001F009L01A01Z01C01.tif\n",
      "Saved image to: validation_results\\60x images\\AssayPlate_Greiner_#655090_C04_T0001F009L01A02Z01C02.tif\n",
      "Saved image to: validation_results\\60x images\\AssayPlate_Greiner_#655090_C04_T0001F009L01A03Z01C03.tif\n",
      "Saved image to: validation_results\\60x images\\AssayPlate_Greiner_#655090_D02_T0001F003L01A01Z01C01.tif\n",
      "Saved image to: validation_results\\60x images\\AssayPlate_Greiner_#655090_D02_T0001F003L01A02Z01C02.tif\n",
      "Saved image to: validation_results\\60x images\\AssayPlate_Greiner_#655090_D02_T0001F003L01A03Z01C03.tif\n",
      "Saved image to: validation_results\\60x images\\AssayPlate_Greiner_#655090_D02_T0001F009L01A01Z01C01.tif\n",
      "Saved image to: validation_results\\60x images\\AssayPlate_Greiner_#655090_D02_T0001F009L01A02Z01C02.tif\n",
      "Saved image to: validation_results\\60x images\\AssayPlate_Greiner_#655090_D02_T0001F009L01A03Z01C03.tif\n",
      "Saved image to: validation_results\\60x images\\AssayPlate_Greiner_#655090_D04_T0001F001L01A01Z01C01.tif\n",
      "Saved image to: validation_results\\60x images\\AssayPlate_Greiner_#655090_D04_T0001F001L01A02Z01C02.tif\n",
      "Saved image to: validation_results\\60x images\\AssayPlate_Greiner_#655090_D04_T0001F001L01A03Z01C03.tif\n",
      "Saved image to: validation_results\\60x images\\AssayPlate_Greiner_#655090_D04_T0001F012L01A01Z01C01.tif\n",
      "Saved image to: validation_results\\60x images\\AssayPlate_Greiner_#655090_D04_T0001F012L01A02Z01C02.tif\n",
      "Saved image to: validation_results\\60x images\\AssayPlate_Greiner_#655090_D04_T0001F012L01A03Z01C03.tif\n"
     ]
    }
   ],
   "source": [
    "output_format = os.path.join(OUTPUT_PATH, file_name_struct)\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "\n",
    "for brightfield, prediction in zip(list_of_brightfield_images, stains):\n",
    "    \n",
    "    well = brightfield.get_property(\"well\")\n",
    "    site = brightfield.get_property(\"site\")\n",
    "    \n",
    "    # Undo the padding required by the model\n",
    "    undo_padding = brightfield.get_property(\"undo_padding\")\n",
    "    prediction = prediction[undo_padding]\n",
    "    \n",
    "    for action in range(3):\n",
    "        file_path = output_format.format(well, site, action + 1, 1)\n",
    "        \n",
    "        prediction_layer = Image.fromarray(prediction[..., action].astype(np.uint16))\n",
    "        prediction_layer.save(file_path)\n",
    "\n",
    "        print(\"Saved image to:\", file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
